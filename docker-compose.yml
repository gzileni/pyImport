version: '3.8'
services:
  db:
    container_name: geo-db
    image: postgis/postgis:14-3.2-alpine
    restart: always
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DATABASE_NAME: ${POSTGRES_DATABASE_NAME}
      PGPORT: ${PGPORT}
    healthcheck:
      test: [ 'CMD-SHELL', 'pg_isready -U ${POSTGRES_DATABASE_NAME}' ]
      interval: 5s
      timeout: 5s
      retries: 5
    ports:
      - ${PGPORT}:${PGPORT}
    networks:
      - geo-network
    volumes:
      - .${PGDATA}:/var/lib/postgresql/data
  
  pgAdmin:
    # wharp-db.hextra.dev
    container_name: geo-pgadmin
    image: dpage/pgadmin4
    restart: always
    environment:
      PGADMIN_DEFAULT_EMAIL: ${PGADMIN_DEFAULT_EMAIL}
      PGADMIN_DEFAULT_PASSWORD: ${PGADMIN_DEFAULT_PASSWORD}
      PGPORT: ${PGPORT}
    networks:
      - geo-network
    ports:
      - '8083:80'
    depends_on:
      - db

  spark-master:
    image: bde2020/spark-master:3.3.0-hadoop3.3
    container_name: spark-master
    ports:
      - "8080:8080"
      - "7077:7077"
    environment:
      - INIT_DAEMON_STEP=setup_spark
    networks:
      - geo-network
  
  spark-worker-1:
    image: bde2020/spark-worker:3.3.0-hadoop3.3
    container_name: spark-worker-1
    depends_on:
      - spark-master
    ports:
      - "8081:8081"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
    networks:
      - geo-network
  
  spark-worker-2:
    image: bde2020/spark-worker:3.3.0-hadoop3.3
    container_name: spark-worker-2
    depends_on:
      - spark-master
    ports:
      - "8082:8081"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
    networks:
      - geo-network
  
  spark-history-server:
      image: bde2020/spark-history-server:3.3.0-hadoop3.3
      container_name: spark-history-server
      depends_on:
        - spark-master
      ports:
        - "18081:18081"
      volumes:
        - ./spark/events:/tmp/spark-events
      networks:
      - geo-network

  import:
    build: ./import
    container_name: geo-import
    image: geo-import
    restart: always
    environment:
      - "SPARK_HOST=spark-master"
    networks:
      - geo-network
    deploy:
      resources:
        limits:
          cpus: '0.75'
          memory: 8000M
        reservations:
          cpus: '0.60'
          memory: 6000M

networks:
   geo-network:
      driver: bridge
      ipam:
         driver: default
         config:
            - subnet: 192.168.199.0/24

volumes:
  db:
    driver: local

